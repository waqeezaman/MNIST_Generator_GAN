{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 140,
      "metadata": {
        "id": "tz6X11qw6WAF"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.losses import BinaryCrossentropy\n",
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UtuZ0AbSNHvH",
        "outputId": "7f45d563-8982-4b41-8d6c-2814260c7f62"
      },
      "execution_count": 141,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 142,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mQWSySvJbhtC",
        "outputId": "d8d6390b-dd04-4f10-a14f-e53e2e83e645"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found GPU at: /device:GPU:0\n"
          ]
        }
      ],
      "source": [
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "  raise SystemError('GPU device not found')\n",
        "print('Found GPU at: {}'.format(device_name))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 143,
      "metadata": {
        "id": "EPaU8Zuo434X"
      },
      "outputs": [],
      "source": [
        "## get data\n",
        "(x_train,y_train),(x_test,y_test) = mnist.load_data()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 144,
      "metadata": {
        "id": "xjfRXnUX4-IC"
      },
      "outputs": [],
      "source": [
        "## normalise data\n",
        "x_train = (x_train.astype('float32')-127.5)  /127.5\n",
        "x_test = (x_test.astype('float32')-127.5)  /127.5\n",
        "\n",
        "images = np.concatenate( [x_train,x_test])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 145,
      "metadata": {
        "id": "8nOE_BF7LB2f"
      },
      "outputs": [],
      "source": [
        "def make_generator_model(latent_vector_size=100):\n",
        "    model = tf.keras.Sequential()\n",
        "\n",
        "    model.add(layers.Dense(7*7*256, use_bias=False, input_shape=(latent_vector_size,)))\n",
        "    model.add(layers.BatchNormalization())\n",
        "    model.add(layers.LeakyReLU())\n",
        "\n",
        "    model.add(layers.Reshape((7, 7, 256)))\n",
        "    assert model.output_shape == (None, 7, 7, 256)  # Note: None is the batch size\n",
        "\n",
        "    layers.Conv2D(256, (4,4), padding='same',strides=(1,1)),\n",
        "    layers.LeakyReLU(),\n",
        "\n",
        "    model.add(layers.Conv2DTranspose(128, (5, 5), strides=(1, 1), padding='same', use_bias=False))\n",
        "    assert model.output_shape == (None, 7, 7, 128)\n",
        "    model.add(layers.BatchNormalization())\n",
        "    model.add(layers.LeakyReLU())\n",
        "\n",
        "    layers.Conv2D(128, (3,3), padding='same',strides=(1,1)),\n",
        "    layers.LeakyReLU(),\n",
        "\n",
        "\n",
        "\n",
        "    model.add(layers.Conv2DTranspose(64, (5, 5), strides=(2, 2), padding='same', use_bias=False))\n",
        "    assert model.output_shape == (None, 14, 14, 64)\n",
        "    model.add(layers.BatchNormalization())\n",
        "    model.add(layers.LeakyReLU())\n",
        "\n",
        "    model.add(layers.Conv2DTranspose(1, (5, 5), strides=(2, 2), padding='same', use_bias=False, activation='tanh'))\n",
        "    assert model.output_shape == (None, 28, 28, 1)\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 146,
      "metadata": {
        "id": "TYTX2-o66alY"
      },
      "outputs": [],
      "source": [
        "## discriminator model\n",
        "def make_discriminator_model():\n",
        "  discriminator = Sequential ([\n",
        "      layers.Conv2D(64, (4,4), input_shape=[28,28,1],padding='same',strides=(2,2)),\n",
        "      layers.LeakyReLU(),\n",
        "      layers.Dropout(0.3),\n",
        "\n",
        "      layers.Conv2D(128, (4,4), strides=(2,2),padding='same'),\n",
        "      layers.LeakyReLU(),\n",
        "      layers.Dropout(0.3),\n",
        "\n",
        "      layers.Flatten(),\n",
        "      layers.Dense(1)\n",
        "\n",
        "  ])\n",
        "  return discriminator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 147,
      "metadata": {
        "id": "AsPPrp6yQAyL"
      },
      "outputs": [],
      "source": [
        "cross_entropy = BinaryCrossentropy(from_logits=True)\n",
        "\n",
        "def discriminator_loss( real_output , fake_output ):\n",
        "\n",
        "  real_loss = cross_entropy( tf.ones_like(real_output ), real_output)\n",
        "\n",
        "  fake_loss = cross_entropy( tf.zeros_like( fake_output ), fake_output)\n",
        "\n",
        "  return real_loss + fake_loss\n",
        "\n",
        "\n",
        "def generator_loss ( fake_output):\n",
        "  return cross_entropy ( tf.ones_like( fake_output), fake_output)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 148,
      "metadata": {
        "id": "1dJd3GKVRHQx"
      },
      "outputs": [],
      "source": [
        "generator_optimizer = tf.keras.optimizers.Adam(1e-4)\n",
        "discriminator_optimizer = tf.keras.optimizers.Adam(1e-4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 149,
      "metadata": {
        "id": "WEVfmvq3Saxh"
      },
      "outputs": [],
      "source": [
        "checkpoint_dir = './drive/MyDrive/GANS/mnist/training_checkpoints'\n",
        "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
        "checkpoint = tf.train.Checkpoint(generator_optimizer=generator_optimizer,\n",
        "                                 discriminator_optimizer=discriminator_optimizer,\n",
        "                                 generator=generator,\n",
        "                                 discriminator=discriminator)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 150,
      "metadata": {
        "id": "SxLIb1HOTPKw"
      },
      "outputs": [],
      "source": [
        "@tf.function\n",
        "def train_step(images):\n",
        "\n",
        "  noise = tf.random.normal(  [batch_size, noise_dim])\n",
        "\n",
        "  ## train discriminator for k steps first, in order to let it get ahead of generator\n",
        "  for k in range(5):\n",
        "    with tf.GradientTape() as disc_tape:\n",
        "      generated_images = generator(noise, training=True)\n",
        "\n",
        "      real_output = discriminator(images, training=True)\n",
        "      fake_output = discriminator(generated_images, training=True)\n",
        "\n",
        "      disc_loss = discriminator_loss(real_output,fake_output)\n",
        "\n",
        "    ## calculate gradient of discriminator\n",
        "    gradients_of_discriminator = disc_tape.gradient(disc_loss, discriminator.trainable_variables)\n",
        "    ## apply gradients\n",
        "    discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator, discriminator.trainable_variables))\n",
        "\n",
        "\n",
        "  with tf.GradientTape() as gen_tape:\n",
        "      generated_images = generator(noise, training=True)\n",
        "\n",
        "      fake_output = discriminator(generated_images, training=True)\n",
        "\n",
        "      gen_loss = generator_loss(fake_output)\n",
        "\n",
        "  ## calculate gradient of discriminator\n",
        "  gradients_of_generator = gen_tape.gradient(gen_loss, generator.trainable_variables)\n",
        "  ## apply gradients\n",
        "  generator_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_variables))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 151,
      "metadata": {
        "id": "otgYF2lDTgtF"
      },
      "outputs": [],
      "source": [
        "def train (dataset, epochs  ):\n",
        "  for epoch in range(epochs):\n",
        "    start = time.time()\n",
        "\n",
        "    for batch in dataset:\n",
        "      train_step( batch )\n",
        "\n",
        "      # Save the model every 15 epochs\n",
        "    if (epoch + 1) % 30 == 0:\n",
        "      checkpoint.save(file_prefix = checkpoint_prefix)\n",
        "      print('Saved At Checkpoint')\n",
        "\n",
        "    print ('Time for epoch {} is {} sec'.format(epoch + 1, time.time()-start))\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 60\n",
        "noise_dim = 8\n",
        "batch_size = 128\n",
        "buffer_size = 70000\n",
        "\n",
        "# batch and shuffle the data\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices(x_train).shuffle(buffer_size).batch(batch_size)\n",
        "\n",
        "generator= make_generator_model(latent_vector_size=noise_dim)\n",
        "discriminator = make_discriminator_model()"
      ],
      "metadata": {
        "id": "JBbvehQLaP9m"
      },
      "execution_count": 152,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 153,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NwZDV0wRX5hF",
        "outputId": "9f9c4cef-3f07-4822-f13d-daa6e09122db"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time for epoch 1 is 41.955997467041016 sec\n",
            "Time for epoch 2 is 33.035178422927856 sec\n",
            "Time for epoch 3 is 32.43982648849487 sec\n",
            "Time for epoch 4 is 32.706997871398926 sec\n",
            "Time for epoch 5 is 32.71799969673157 sec\n",
            "Time for epoch 6 is 32.606693983078 sec\n",
            "Time for epoch 7 is 32.60512018203735 sec\n",
            "Time for epoch 8 is 32.598090410232544 sec\n",
            "Time for epoch 9 is 32.716230154037476 sec\n",
            "Time for epoch 10 is 32.688552141189575 sec\n",
            "Time for epoch 11 is 32.642643213272095 sec\n",
            "Time for epoch 12 is 32.61276197433472 sec\n",
            "Time for epoch 13 is 32.745545387268066 sec\n",
            "Time for epoch 14 is 32.74663734436035 sec\n",
            "Time for epoch 15 is 32.6513512134552 sec\n",
            "Time for epoch 16 is 32.6789927482605 sec\n",
            "Time for epoch 17 is 32.714073181152344 sec\n",
            "Time for epoch 18 is 32.718583822250366 sec\n",
            "Time for epoch 19 is 32.715909242630005 sec\n",
            "Time for epoch 20 is 32.690837383270264 sec\n",
            "Time for epoch 21 is 32.722490549087524 sec\n",
            "Time for epoch 22 is 32.698795795440674 sec\n",
            "Time for epoch 23 is 32.72039079666138 sec\n",
            "Time for epoch 24 is 32.70021629333496 sec\n",
            "Time for epoch 25 is 32.70884966850281 sec\n",
            "Time for epoch 26 is 32.71696758270264 sec\n",
            "Time for epoch 27 is 32.70356225967407 sec\n",
            "Time for epoch 28 is 32.714038372039795 sec\n",
            "Time for epoch 29 is 32.71254587173462 sec\n",
            "Saved At Checkpoint\n",
            "Time for epoch 30 is 32.91675615310669 sec\n",
            "Time for epoch 31 is 32.682090044021606 sec\n",
            "Time for epoch 32 is 32.75244474411011 sec\n",
            "Time for epoch 33 is 32.72423601150513 sec\n",
            "Time for epoch 34 is 32.69015884399414 sec\n",
            "Time for epoch 35 is 32.72792983055115 sec\n",
            "Time for epoch 36 is 32.70717906951904 sec\n",
            "Time for epoch 37 is 32.73609805107117 sec\n",
            "Time for epoch 38 is 32.71730065345764 sec\n",
            "Time for epoch 39 is 32.74906849861145 sec\n",
            "Time for epoch 40 is 32.71147418022156 sec\n",
            "Time for epoch 41 is 32.7070574760437 sec\n",
            "Time for epoch 42 is 32.756160736083984 sec\n",
            "Time for epoch 43 is 32.67319583892822 sec\n",
            "Time for epoch 44 is 32.694358587265015 sec\n",
            "Time for epoch 45 is 32.66548299789429 sec\n",
            "Time for epoch 46 is 32.63735508918762 sec\n",
            "Time for epoch 47 is 32.6329448223114 sec\n",
            "Time for epoch 48 is 32.62439203262329 sec\n",
            "Time for epoch 49 is 32.637338399887085 sec\n",
            "Time for epoch 50 is 32.60480189323425 sec\n",
            "Time for epoch 51 is 32.64677691459656 sec\n",
            "Time for epoch 52 is 32.69010615348816 sec\n",
            "Time for epoch 53 is 32.6839599609375 sec\n",
            "Time for epoch 54 is 32.7270565032959 sec\n",
            "Time for epoch 55 is 32.7609977722168 sec\n",
            "Time for epoch 56 is 32.77384161949158 sec\n",
            "Time for epoch 57 is 32.69616508483887 sec\n",
            "Time for epoch 58 is 32.64004731178284 sec\n",
            "Time for epoch 59 is 32.62634801864624 sec\n",
            "Saved At Checkpoint\n",
            "Time for epoch 60 is 33.30301237106323 sec\n"
          ]
        }
      ],
      "source": [
        "train ( train_dataset, epochs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 154,
      "metadata": {
        "id": "lI-TdpVpDpkm"
      },
      "outputs": [],
      "source": [
        "generator.save('./drive/MyDrive/GANS/mnist/Models/60epochs_k=5_latent_vector=8_model.keras')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Inputs { run: \"auto\", form-width: \"300px\", display-mode: \"form\" }\n",
        "input = np.ones(shape=(1,10))\n",
        "i0 = 0  #@param {type:\"slider\", min:-3, max:3, step:0.05}\n",
        "i1 = -0.05  #@param {type:\"slider\", min:-3, max:3, step:0.05}\n",
        "i2 = -2.2  #@param {type:\"slider\", min:-3, max:3, step:0.05}\n",
        "i3 = 2.85  #@param {type:\"slider\", min:-3, max:3, step:0.05}\n",
        "i4 = -1.1  #@param {type:\"slider\", min:-3, max:3, step:0.05}\n",
        "i5 = 0  #@param {type:\"slider\", min:-3, max:3, step:0.05}\n",
        "i6 = 0  #@param {type:\"slider\", min:-3, max:3, step:0.05}\n",
        "i7 = 0#@param {type:\"slider\", min:-3, max:3, step:0.05}\n",
        "# i8 = 2.55#@param {type:\"slider\", min:-3, max:3, step:0.05}\n",
        "# i9 = -2.6#@param {type:\"slider\", min:-3, max:3, step:0.05}\n",
        "\n",
        "\n",
        "buffer =np.array([i0,i1,i2,i3,i4,i4,i5,i6,i7])##,i8,i9])#,dtype=float)\n",
        "\n",
        "input = np.ndarray(shape=(1,8),buffer=buffer)\n",
        "image = generator( input)\n",
        "plt.imshow( image[0,:,:,0],cmap='gray'  )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 447
        },
        "id": "iGi-NXZHKh-_",
        "outputId": "8f57df2f-47fb-4686-8f26-c392d5e3c58c"
      },
      "execution_count": 229,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7b37880fbd90>"
            ]
          },
          "metadata": {},
          "execution_count": 229
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAaAAAAGdCAYAAABU0qcqAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAbiUlEQVR4nO3df2xV9f3H8dcttBeU9mKt7e2VHxZQ2EC6DaR2aoejoXQL41c2f/2Bi5GgxUyZP9Jlim5m3TBxxgV//LHQGeSXi8BkCwarLXErGFBCzLaGkm4t0hYl4d5SaMH28/2Dr3deaIFzubfv3vJ8JJ+k95zzvufdw6GvnntPP9fnnHMCAGCApVk3AAC4MhFAAAATBBAAwAQBBAAwQQABAEwQQAAAEwQQAMAEAQQAMDHcuoFz9fb26siRI8rMzJTP57NuBwDgkXNOHR0dCoVCSkvr/zpn0AXQkSNHNHbsWOs2AACXqaWlRWPGjOl3/aB7CS4zM9O6BQBAAlzs53nSAmjNmjW64YYbNGLECBUVFemjjz66pDpedgOAoeFiP8+TEkCbNm3SypUrtWrVKn388ccqLCxUWVmZjh49mozdAQBSkUuCWbNmuYqKiujjnp4eFwqFXFVV1UVrw+Gwk8RgMBiMFB/hcPiCP+8TfgV0+vRp7du3T6WlpdFlaWlpKi0tVX19/Xnbd3d3KxKJxAwAwNCX8AD64osv1NPTo7y8vJjleXl5amtrO2/7qqoqBQKB6OAOOAC4MpjfBVdZWalwOBwdLS0t1i0BAAZAwv8OKCcnR8OGDVN7e3vM8vb2dgWDwfO29/v98vv9iW4DADDIJfwKKCMjQzNmzFBNTU10WW9vr2pqalRcXJzo3QEAUlRSZkJYuXKlli5dqpkzZ2rWrFl66aWX1NnZqZ/+9KfJ2B0AIAUlJYDuuusuff7553rmmWfU1tamb33rW9qxY8d5NyYAAK5cPuecs27i6yKRiAKBgHUbAIDLFA6HlZWV1e9687vgAABXJgIIAGCCAAIAmCCAAAAmCCAAgAkCCABgggACAJgggAAAJgggAIAJAggAYIIAAgCYIIAAACYIIACACQIIAGCCAAIAmCCAAAAmCCAAgAkCCABgggACAJgggAAAJgggAIAJAggAYIIAAgCYIIAAACYIIACACQIIAGCCAAIAmCCAAAAmCCAAgAkCCABgggACAJgggAAAJgggAIAJAggAYIIAAgCYIIAAACYIIACACQIIAGCCAAIAmCCAAAAmCCAAgAkCCABgggACAJgggAAAJgggAIAJAggAYIIAAgCYIIAAACYIIACACQIIAGCCAAIAmCCAAAAmhls3ACSDz+eLq27MmDGea6qrqz3XlJSUeK754osvPNf8+c9/9lwjSTNnzvRcc/DgQc81y5Yt81zT1dXluQaDE1dAAAATBBAAwETCA+jZZ5+Vz+eLGVOmTEn0bgAAKS4p7wFNnTpV77333v92Mpy3mgAAsZKSDMOHD1cwGEzGUwMAhoikvAd08OBBhUIhTZgwQffdd5+am5v73ba7u1uRSCRmAACGvoQHUFFRkaqrq7Vjxw69+uqrampq0h133KGOjo4+t6+qqlIgEIiOsWPHJrolAMAglPAAKi8v149//GNNnz5dZWVl+tvf/qbjx49r8+bNfW5fWVmpcDgcHS0tLYluCQAwCCX97oDRo0frpptuUmNjY5/r/X6//H5/stsAAAwySf87oBMnTujQoUPKz89P9q4AACkk4QH0+OOPq66uTv/5z3/0j3/8Q4sWLdKwYcN0zz33JHpXAIAUlvCX4A4fPqx77rlHx44d03XXXafbb79du3fv1nXXXZfoXQEAUljCA2jjxo2JfkrAs8zMzLjq8vLyPNccPnzYc82pU6c815w+fdpzzezZsz3XSNKkSZM813z729/2XPPGG294rvn6H7kjtTEXHADABAEEADBBAAEATBBAAAATBBAAwAQBBAAwQQABAEwQQAAAEwQQAMAEAQQAMEEAAQBMEEAAABM+55yzbuLrIpGIAoGAdRtXlOHD45uTdtOmTZ5r0tPTPddMnTrVc028H+3e09PjuSaeiUUH6hz3+XwDWudVfx9UeSE33nhjEjpBMoTDYWVlZfW7nisgAIAJAggAYIIAAgCYIIAAACYIIACACQIIAGCCAAIAmCCAAAAmCCAAgAkCCABgggACAJgggAAAJgggAICJ+KZBxpAyf/78uOoWLVqU4E76NlAzM0vxzdY9YsSIJHSSGPHM7i1Jw4YNS3Anfevq6hqQ/WBw4goIAGCCAAIAmCCAAAAmCCAAgAkCCABgggACAJgggAAAJgggAIAJAggAYIIAAgCYIIAAACYIIACACSYjhU6fPh1X3alTpzzX+P3+uPblVVrawP1u5ZzzXBPPJKENDQ2ea959913PNZK0YsUKzzXx/NvGe+5haOAKCABgggACAJgggAAAJgggAIAJAggAYIIAAgCYIIAAACYIIACACQIIAGCCAAIAmCCAAAAmCCAAgAkmI4X++te/xlWXmZnpuSY9Pd1zzbRp0zzXzJw503ONJF1zzTWeaz788EPPNc3NzZ5rDh8+7Lkm3klZv/vd73quufXWWz3XBAIBzzU+n89zTTwTxiL5uAICAJgggAAAJjwH0K5duzR//nyFQiH5fD5t3bo1Zr1zTs8884zy8/M1cuRIlZaW6uDBg4nqFwAwRHgOoM7OThUWFmrNmjV9rl+9erVefvllvfbaa9qzZ4+uvvpqlZWVqaur67KbBQAMHZ5vQigvL1d5eXmf65xzeumll/TLX/5SCxYskCS98cYbysvL09atW3X33XdfXrcAgCEjoe8BNTU1qa2tTaWlpdFlgUBARUVFqq+v77Omu7tbkUgkZgAAhr6EBlBbW5skKS8vL2Z5Xl5edN25qqqqFAgEomPs2LGJbAkAMEiZ3wVXWVmpcDgcHS0tLdYtAQAGQEIDKBgMSpLa29tjlre3t0fXncvv9ysrKytmAACGvoQGUEFBgYLBoGpqaqLLIpGI9uzZo+Li4kTuCgCQ4jzfBXfixAk1NjZGHzc1NWn//v3Kzs7WuHHj9Oijj+r555/XjTfeqIKCAj399NMKhUJauHBhIvsGAKQ4zwG0d+9e3XnnndHHK1eulCQtXbpU1dXVevLJJ9XZ2ally5bp+PHjuv3227Vjxw6NGDEicV0DAFKezw2yWfoikUhcExQCOF88E3dK0rp16zzX/OQnP/FcE89NR4WFhZ5rOjo6PNfg8oXD4Qu+r29+FxwA4MpEAAEATBBAAAATBBAAwAQBBAAwQQABAEwQQAAAEwQQAMAEAQQAMEEAAQBMEEAAABMEEADABAEEADDh+eMYAKSOtLT4fsf85je/6bnmyy+/9Fzz+eefe67JyMjwXIPBiSsgAIAJAggAYIIAAgCYIIAAACYIIACACQIIAGCCAAIAmCCAAAAmCCAAgAkCCABgggACAJgggAAAJpiMFBjC5s6dG1fdlClTPNc45zzX7N2713NNOBz2XIPBiSsgAIAJAggAYIIAAgCYIIAAACYIIACACQIIAGCCAAIAmCCAAAAmCCAAgAkCCABgggACAJgggAAAJpiMFEgRGRkZnms2bNgQ177S09M913R0dHiuefvttz3X9PT0eK7B4MQVEADABAEEADBBAAEATBBAAAATBBAAwAQBBAAwQQABAEwQQAAAEwQQAMAEAQQAMEEAAQBMEEAAABNMRgqkiHXr1nmuGTVqVFz7OnXqlOeajRs3eq7Zu3ev5xrnnOcaDE5cAQEATBBAAAATngNo165dmj9/vkKhkHw+n7Zu3Rqz/v7775fP54sZ8+bNS1S/AIAhwnMAdXZ2qrCwUGvWrOl3m3nz5qm1tTU64v1QLADA0OX5JoTy8nKVl5dfcBu/369gMBh3UwCAoS8p7wHV1tYqNzdXkydP1kMPPaRjx471u213d7cikUjMAAAMfQkPoHnz5umNN95QTU2Nfve736murk7l5eX9fo57VVWVAoFAdIwdOzbRLQEABqGE/x3Q3XffHf365ptv1vTp0zVx4kTV1tZqzpw5521fWVmplStXRh9HIhFCCACuAEm/DXvChAnKyclRY2Njn+v9fr+ysrJiBgBg6Et6AB0+fFjHjh1Tfn5+sncFAEghnl+CO3HiRMzVTFNTk/bv36/s7GxlZ2frueee05IlSxQMBnXo0CE9+eSTmjRpksrKyhLaOAAgtXkOoL179+rOO++MPv7q/ZulS5fq1Vdf1YEDB/SnP/1Jx48fVygU0ty5c/XrX/9afr8/cV0DAFKe5wCaPXv2BScDfPfddy+rIeBKcOutt3quWbhwoeeaeCfu/OijjzzXnDsryqU4efKk5xoMHcwFBwAwQQABAEwQQAAAEwQQAMAEAQQAMEEAAQBMEEAAABMEEADABAEEADBBAAEATBBAAAATBBAAwAQBBAAwkfCP5AZSWTwfGzJx4kTPNX/5y1881wwf7v2/a2dnp+caSXrllVc819TW1nquOXPmjOcaDB1cAQEATBBAAAATBBAAwAQBBAAwQQABAEwQQAAAEwQQAMAEAQQAMEEAAQBMEEAAABMEEADABAEEADDBZKQY9Hw+n+eaqVOnxrWvyspKzzWhUMhzTW9vr+eazz77zHPNb37zG881krRlyxbPNfF8T7iycQUEADBBAAEATBBAAAATBBAAwAQBBAAwQQABAEwQQAAAEwQQAMAEAQQAMEEAAQBMEEAAABMEEADABJORYkClpXn/nScQCHiuefjhhz3XSNKPfvQjzzWdnZ2eazZv3uy55oUXXvBc09LS4rkGGChcAQEATBBAAAATBBAAwAQBBAAwQQABAEwQQAAAEwQQAMAEAQQAMEEAAQBMEEAAABMEEADABAEEADDBZKQYUBkZGZ5rZs6c6blm/vz5nmskafhw7/8lPv/8c88127Zt81zz2Wefea4BBjOugAAAJgggAIAJTwFUVVWlW265RZmZmcrNzdXChQvV0NAQs01XV5cqKip07bXXatSoUVqyZIna29sT2jQAIPV5CqC6ujpVVFRo9+7d2rlzp86cOaO5c+fGfCDXY489pnfeeUdvvfWW6urqdOTIES1evDjhjQMAUpund1x37NgR87i6ulq5ubnat2+fSkpKFA6H9cc//lHr16/X97//fUnS2rVr9Y1vfEO7d+/WrbfemrjOAQAp7bLeAwqHw5Kk7OxsSdK+fft05swZlZaWRreZMmWKxo0bp/r6+j6fo7u7W5FIJGYAAIa+uAOot7dXjz76qG677TZNmzZNktTW1qaMjAyNHj06Ztu8vDy1tbX1+TxVVVUKBALRMXbs2HhbAgCkkLgDqKKiQp9++qk2btx4WQ1UVlYqHA5HR0tLy2U9HwAgNcT1h6grVqzQ9u3btWvXLo0ZMya6PBgM6vTp0zp+/HjMVVB7e7uCwWCfz+X3++X3++NpAwCQwjxdATnntGLFCm3ZskXvv/++CgoKYtbPmDFD6enpqqmpiS5raGhQc3OziouLE9MxAGBI8HQFVFFRofXr12vbtm3KzMyMvq8TCAQ0cuRIBQIBPfDAA1q5cqWys7OVlZWlRx55RMXFxdwBBwCI4SmAXn31VUnS7NmzY5avXbtW999/vyTp97//vdLS0rRkyRJ1d3errKxMr7zySkKaBQAMHT7nnLNu4usikYgCgYB1G7gE6enpnmtef/11zzX33nuv55q0tPjur4nnppqnnnrKc01ra6vnGsTP5/MNWF08NT09PZ5rUkE4HFZWVla/65kLDgBgggACAJgggAAAJgggAIAJAggAYIIAAgCYIIAAACYIIACACQIIAGCCAAIAmCCAAAAmCCAAgAkCCABgIq5PRAUk6csvv/RcU1dX57lm8eLFnmtefPFFzzWS9Pzzz3uu6e3tjWtfGDgDOek/58Ol4woIAGCCAAIAmCCAAAAmCCAAgAkCCABgggACAJgggAAAJgggAIAJAggAYIIAAgCYIIAAACYIIACACZ8byFn6LkEkElEgELBuA0kyatQozzVTpkzxXPPxxx97rpGYSBJIpHA4rKysrH7XcwUEADBBAAEATBBAAAATBBAAwAQBBAAwQQABAEwQQAAAEwQQAMAEAQQAMEEAAQBMEEAAABMEEADABJORAgCSgslIAQCDEgEEADBBAAEATBBAAAATBBAAwAQBBAAwQQABAEwQQAAAEwQQAMAEAQQAMEEAAQBMEEAAABMEEADABAEEADBBAAEATHgKoKqqKt1yyy3KzMxUbm6uFi5cqIaGhphtZs+eLZ/PFzOWL1+e0KYBAKnPUwDV1dWpoqJCu3fv1s6dO3XmzBnNnTtXnZ2dMds9+OCDam1tjY7Vq1cntGkAQOob7mXjHTt2xDyurq5Wbm6u9u3bp5KSkujyq666SsFgMDEdAgCGpMt6DygcDkuSsrOzY5a/+eabysnJ0bRp01RZWamTJ0/2+xzd3d2KRCIxAwBwBXBx6unpcT/84Q/dbbfdFrP89ddfdzt27HAHDhxw69atc9dff71btGhRv8+zatUqJ4nBYDAYQ2yEw+EL5kjcAbR8+XI3fvx419LScsHtampqnCTX2NjY5/quri4XDoejo6WlxfygMRgMBuPyx8UCyNN7QF9ZsWKFtm/frl27dmnMmDEX3LaoqEiS1NjYqIkTJ5633u/3y+/3x9MGACCFeQog55weeeQRbdmyRbW1tSooKLhozf79+yVJ+fn5cTUIABiaPAVQRUWF1q9fr23btikzM1NtbW2SpEAgoJEjR+rQoUNav369fvCDH+jaa6/VgQMH9Nhjj6mkpETTp09PyjcAAEhRXt73UT+v861du9Y551xzc7MrKSlx2dnZzu/3u0mTJrknnnjioq8Dfl04HDZ/3ZLBYDAYlz8u9rPf9//BMmhEIhEFAgHrNgAAlykcDisrK6vf9cwFBwAwQQABAEwQQAAAEwQQAMAEAQQAMEEAAQBMEEAAABMEEADABAEEADBBAAEATBBAAAATBBAAwAQBBAAwQQABAEwQQAAAEwQQAMAEAQQAMEEAAQBMEEAAABMEEADABAEEADBBAAEATBBAAAATBBAAwAQBBAAwMegCyDln3QIAIAEu9vN80AVQR0eHdQsAgAS42M9znxtklxy9vb06cuSIMjMz5fP5YtZFIhGNHTtWLS0tysrKMurQHsfhLI7DWRyHszgOZw2G4+CcU0dHh0KhkNLS+r/OGT6APV2StLQ0jRkz5oLbZGVlXdEn2Fc4DmdxHM7iOJzFcTjL+jgEAoGLbjPoXoIDAFwZCCAAgImUCiC/369Vq1bJ7/dbt2KK43AWx+EsjsNZHIezUuk4DLqbEAAAV4aUugICAAwdBBAAwAQBBAAwQQABAEykTACtWbNGN9xwg0aMGKGioiJ99NFH1i0NuGeffVY+ny9mTJkyxbqtpNu1a5fmz5+vUCgkn8+nrVu3xqx3zumZZ55Rfn6+Ro4cqdLSUh08eNCm2SS62HG4//77zzs/5s2bZ9NsklRVVemWW25RZmamcnNztXDhQjU0NMRs09XVpYqKCl177bUaNWqUlixZovb2dqOOk+NSjsPs2bPPOx+WL19u1HHfUiKANm3apJUrV2rVqlX6+OOPVVhYqLKyMh09etS6tQE3depUtba2RseHH35o3VLSdXZ2qrCwUGvWrOlz/erVq/Xyyy/rtdde0549e3T11VerrKxMXV1dA9xpcl3sOEjSvHnzYs6PDRs2DGCHyVdXV6eKigrt3r1bO3fu1JkzZzR37lx1dnZGt3nsscf0zjvv6K233lJdXZ2OHDmixYsXG3adeJdyHCTpwQcfjDkfVq9ebdRxP1wKmDVrlquoqIg+7unpcaFQyFVVVRl2NfBWrVrlCgsLrdswJclt2bIl+ri3t9cFg0H3wgsvRJcdP37c+f1+t2HDBoMOB8a5x8E555YuXeoWLFhg0o+Vo0ePOkmurq7OOXf23z49Pd299dZb0W3+9a9/OUmuvr7eqs2kO/c4OOfc9773Pfezn/3MrqlLMOivgE6fPq19+/aptLQ0uiwtLU2lpaWqr6837MzGwYMHFQqFNGHCBN13331qbm62bslUU1OT2traYs6PQCCgoqKiK/L8qK2tVW5uriZPnqyHHnpIx44ds24pqcLhsCQpOztbkrRv3z6dOXMm5nyYMmWKxo0bN6TPh3OPw1fefPNN5eTkaNq0aaqsrNTJkyct2uvXoJuM9FxffPGFenp6lJeXF7M8Ly9P//73v426slFUVKTq6mpNnjxZra2teu6553THHXfo008/VWZmpnV7Jtra2iSpz/Pjq3VXinnz5mnx4sUqKCjQoUOH9Itf/ELl5eWqr6/XsGHDrNtLuN7eXj366KO67bbbNG3aNElnz4eMjAyNHj06ZtuhfD70dRwk6d5779X48eMVCoV04MABPfXUU2poaNDbb79t2G2sQR9A+J/y8vLo19OnT1dRUZHGjx+vzZs364EHHjDsDIPB3XffHf365ptv1vTp0zVx4kTV1tZqzpw5hp0lR0VFhT799NMr4n3QC+nvOCxbtiz69c0336z8/HzNmTNHhw4d0sSJEwe6zT4N+pfgcnJyNGzYsPPuYmlvb1cwGDTqanAYPXq0brrpJjU2Nlq3Yuarc4Dz43wTJkxQTk7OkDw/VqxYoe3bt+uDDz6I+fiWYDCo06dP6/jx4zHbD9Xzob/j0JeioiJJGlTnw6APoIyMDM2YMUM1NTXRZb29vaqpqVFxcbFhZ/ZOnDihQ4cOKT8/37oVMwUFBQoGgzHnRyQS0Z49e6748+Pw4cM6duzYkDo/nHNasWKFtmzZovfff18FBQUx62fMmKH09PSY86GhoUHNzc1D6ny42HHoy/79+yVpcJ0P1ndBXIqNGzc6v9/vqqur3T//+U+3bNkyN3r0aNfW1mbd2oD6+c9/7mpra11TU5P7+9//7kpLS11OTo47evSodWtJ1dHR4T755BP3ySefOEnuxRdfdJ988on773//65xz7re//a0bPXq027Ztmztw4IBbsGCBKygocKdOnTLuPLEudBw6Ojrc448/7urr611TU5N777333He+8x134403uq6uLuvWE+ahhx5ygUDA1dbWutbW1ug4efJkdJvly5e7cePGuffff9/t3bvXFRcXu+LiYsOuE+9ix6GxsdH96le/cnv37nVNTU1u27ZtbsKECa6kpMS481gpEUDOOfeHP/zBjRs3zmVkZLhZs2a53bt3W7c04O666y6Xn5/vMjIy3PXXX+/uuusu19jYaN1W0n3wwQdO0nlj6dKlzrmzt2I//fTTLi8vz/n9fjdnzhzX0NBg23QSXOg4nDx50s2dO9ddd911Lj093Y0fP949+OCDQ+6XtL6+f0lu7dq10W1OnTrlHn74YXfNNde4q666yi1atMi1trbaNZ0EFzsOzc3NrqSkxGVnZzu/3+8mTZrknnjiCRcOh20bPwcfxwAAMDHo3wMCAAxNBBAAwAQBBAAwQQABAEwQQAAAEwQQAMAEAQQAMEEAAQBMEEAAABMEEADABAEEADBBAAEATPwfbFO57bi0D/cAAAAASUVORK5CYII=\n"
          },
          "metadata": {}
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}